{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.mnist_fashion_data import *\n",
    "from optimization.hyperparameters import *\n",
    "from optimization.opti import *\n",
    "from models.discriminator import *\n",
    "from models.generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vanilla GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan=False\n",
    "with_normalization=True\n",
    "\n",
    "mnist_data = MnistFashionData(path=\"./data/fashion-mnist_train.csv\", cgan=cgan, with_normalization=with_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "n_epochs = 200\n",
    "hyperparams = Hyperparameters(n_epochs=n_epochs, cgan=cgan, latent_dim=latent_dim, lr=1e-04)\n",
    "fixed_noise_vect = torch.randn((hyperparams.batch_size,hyperparams.input_dim_gen)).to(hyperparams.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0.0001\n",
      "cpu\n",
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(hyperparams.input_dim_gen)\n",
    "print(hyperparams.lr)\n",
    "print(hyperparams.device)\n",
    "print(fixed_noise_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc -----------------\n",
      "n_inputs :  128\n",
      "n_output :  64\n",
      "disc -----------------\n",
      "n_inputs :  64\n",
      "n_output :  32\n",
      "disc -----------------\n",
      "n_inputs :  32\n",
      "n_output :  16\n",
      "----------------- gen Encoder -----------------\n",
      "i :  0\n",
      "n_inputs :  256\n",
      "n_output :  128\n",
      "-------------------------------------\n",
      "i :  1\n",
      "n_inputs :  128\n",
      "n_output :  64\n",
      "-------------------------------------\n",
      "----------------- gen Bottleneck -----------------\n",
      "i :  0\n",
      "n_output :  64\n",
      "-------------------------------------\n",
      "i :  1\n",
      "n_output :  64\n",
      "-------------------------------------\n",
      "----------------- gen Decoder -----------------\n",
      "i :  0\n",
      "n_inputs :  64\n",
      "n_output :  128\n",
      "-------------------------------------\n",
      "i :  1\n",
      "n_inputs :  128\n",
      "n_output :  256\n",
      "-------------------------------------\n",
      "----------------- output layer -----------------\n",
      "in_features :  256\n",
      "out_features :  784\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "disc = Discriminator(cgan=cgan, \n",
    "                     n_inputs=hyperparams.img_dim, \n",
    "                     n_classes=hyperparams.n_classes,  \n",
    "                     output_dim=hyperparams.n_output_disc, \n",
    "                     alpha_relu=hyperparams.alpha_relu,\n",
    "                     norm_type='bn').to(hyperparams.device)\n",
    "\n",
    "gen = Generator(cgan=cgan, \n",
    "                n_inputs=hyperparams.latent_dim, \n",
    "                img_dim=hyperparams.img_dim, \n",
    "                n_classes=hyperparams.n_classes, \n",
    "                alpha_relu=hyperparams.alpha_relu,\n",
    "                norm_type='bn').to(hyperparams.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (encoder): Sequential(\n",
       "    (0): LinearLayer(\n",
       "      (linear): Linear(in_features=784, out_features=128, bias=True)\n",
       "      (activation): ActivationLayer(\n",
       "        (activation): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (norm): NormalizationLayer()\n",
       "    )\n",
       "    (1): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (out_layer): LinearLayer(\n",
       "    (linear): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (activation): ActivationLayer(\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (norm): NormalizationLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (encoder): Sequential(\n",
       "    (0): LinearLayer(\n",
       "      (linear): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (activation): ActivationLayer(\n",
       "        (activation): LeakyReLU(negative_slope=0.15)\n",
       "      )\n",
       "      (norm): NormalizationLayer(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Sequential(\n",
       "    (0): ConvResidualBlock(\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvResidualBlock(\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvResidualBlock(\n",
       "      (identity): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): Conv2DLayer(\n",
       "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (activation): ActivationLayer(\n",
       "          (activation): LeakyReLU(negative_slope=0.15)\n",
       "        )\n",
       "        (norm): NormalizationLayer(\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (out_layer): LinearLayer(\n",
       "    (linear): Linear(in_features=262144, out_features=784, bias=True)\n",
       "    (activation): ActivationLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.15)\n",
       "    )\n",
       "    (norm): NormalizationLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvResidualBlock(\n",
       "  (identity): Conv2DLayer(\n",
       "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (activation): ActivationLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.15)\n",
       "    )\n",
       "    (norm): NormalizationLayer(\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2DLayer(\n",
       "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (activation): ActivationLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.15)\n",
       "    )\n",
       "    (norm): NormalizationLayer(\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2DLayer(\n",
       "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (activation): ActivationLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.15)\n",
       "    )\n",
       "    (norm): NormalizationLayer(\n",
       "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.encoder[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization = Optimization(gen, disc, hyperparams, cgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Started training a GAN on the MNIST Fashion dataset...\n",
      "epoch =  0  --------------------------------------------------------\n",
      "noise shape :  torch.Size([32, 256, 64, 64])\n",
      "LinearLayer input shape :  torch.Size([32, 256, 64, 64])\n",
      "1-LinearLayer output shape :  torch.Size([32, 256, 64, 256])\n",
      "2-LinearLayer output shape :  torch.Size([32, 256, 64, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ea10fa493ebe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"vanilla\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\admin\\Desktop\\AI & Deep Learning\\Deep Learning projects\\Generative-Adversarial-Networks\\optimization\\opti.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataloader, steps_train_disc, n_channels, experiment, h, w)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"noise shape : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mfake_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fake_data shape : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mdisc_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Desktop\\AI & Deep Learning\\Deep Learning projects\\Generative-Adversarial-Networks\\models\\generator.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoder output shape : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Desktop\\AI & Deep Learning\\Deep Learning projects\\Generative-Adversarial-Networks\\models\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0midentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\admin\\Desktop\\AI & Deep Learning\\Deep Learning projects\\Generative-Adversarial-Networks\\models\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm_before\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization.train(mnist_data.dataloader, experiment=\"vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit5d1453442e8543df8126f0c5c89733bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
